{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "176f7bdc",
   "metadata": {},
   "source": [
    "### Notebook - Running Spark on OCI Dataflow using PySpark and Spark SQL\n",
    "<details>\n",
    "<summary><font size=\"2\">Check OCI Dataflow documentation for policies required;</font></summary>\n",
    "<li><a href=\"https://docs.public.oneportal.content.oci.oraclecloud.com/en-us/iaas/data-flow/using/policies-data-flow-studio.htm#policies-data-flow-studio\">Policies Required to Integrate Data Flow and Data Science</a></li>\n",
    "</details>",
    "<details>",
    "<summary><font size=\"2\">Check that the data science notebook session has privileges on OCI Dataflow family and any dependencies;</font></summary>\n",
    "\n",
    "```ALL {resource.type = 'datasciencenotebooksession', resource.compartment.id = '<compartment_id>'}```\n",
    "\n",
    "</details>",
    "<details>",
    "<summary><font size=\"2\">Policy for Data Science to manage OCI Data Flow</font></summary>\n",
    "\n",
    "```allow dynamic-group <ds-dynamic-group> to manage dataflow-family in compartment '<your-compartment-name>'```\n",
    "\n",
    "</details>",
    "<details>",
    "<summary><font size=\"2\">Policy statements for logging</font></summary>\n",
    "\n",
    "```allow dynamic-group <ds-dynamic-group> to manage log-groups in compartment '<your-compartment-name>'```\n",
    "```allow dynamic-group <ds-dynamic-group> to manage log-content in compartment '<your-compartment-name>'```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9a0632d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ads\n",
    "ads.set_auth(\"resource_principal\") # Supported values: resource_principal, api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22299eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your valuues;\n",
    "#  compartment id for creating the compute/application in OCI Dataflow\n",
    "#  bucket for writing OCI Dataflow logs\n",
    "#  namespace your OCI Object Storage namespace\n",
    "#  driver_shape ie. VM.Standard.E4.Flex\n",
    "#  executor_shape ie. VM.Standard.E4.Flex\n",
    "# \n",
    "#\n",
    "#Non- autoscaling create session command in New Compute - this will print a session id that you could reconnect to  \n",
    "import json\n",
    "command = {\n",
    "    \"compartmentId\": \"<your_compartment_id>\",\n",
    "    \"displayName\": \"Data Analysis in Python\",\n",
    "    \"language\": \"PYTHON\",\n",
    "    \"sparkVersion\": \"3.2.1\",\n",
    "    \"driverShape\": \"<driver_shape>\",\n",
    "    \"executorShape\": \"<executor_shape>\",\n",
    "    \"driverShapeConfig\":{\"ocpus\":1,\"memoryInGBs\":16},\n",
    "    \"executorShapeConfig\":{\"ocpus\":1,\"memoryInGBs\":16},\n",
    "    \"numExecutors\": 1,\n",
    "    \"type\": \"SESSION\",\n",
    "    \"logsBucketUri\": \"oci://<bucket>@<namespace>/\",\n",
    "    \"configuration\": {\"spark.oracle.datasource.enabled\":\"true\"}\n",
    "}\n",
    "command = f'\\'{json.dumps(command)}\\''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c8e061c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataflow.magics extension is already loaded. To reload it, use:\n",
      "  %reload_ext dataflow.magics\n"
     ]
    }
   ],
   "source": [
    "load_ext dataflow.magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49a73beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table>\n",
       "  <tr>\n",
       "    <th style=\"text-align:left\">Magic</th>\n",
       "    <th style=\"text-align:left\">Example</th>\n",
       "    <th style=\"text-align:left\">Explanation</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>create_session</td>\n",
       "    <td  style=\"text-align:left\">%create_session -l python -c '{\"compartmentId\":\"Data Flow Run resource compartment OCID\",\"displayName\":\"SessionApp\",\"sparkVersion\":\"3.2.1\",\"driverShape\":\"VM.Standard2.1\",\"executorShape\":\"VM.Standard2.1\",\"numExecutors\":1,\"archiveUri\":\"Object Storage URL for Data Flow zip archive.\",\"metastoreId\":\"optional metastore OCID\",\"configuration\":{      \"spark.archives\":\"oci://bucket@namespace/path/to/conda/pack\",      #optional property to use Dataflow 'Run' resource to access OCI resources.\n",
       "      \"dataflow.auth\":\"resource_principal\"   }}'</td>\n",
       "    <td style=\"text-align:left\">Creates new session by providing session details.<br/><br/><b>Example command for Flex shapes :</b><br/>\n",
       "    %create_session -l python -c '{\"compartmentId\":\"Data Flow Run resource compartment OCID\",\"displayName\":\"SessionApp\",\"sparkVersion\":\"3.2.1\",\"driverShape\":\"VM.Standard.E4.Flex\",\"executorShape\":\"VM.Standard.E4.Flex\",\"numExecutors\":1,\"driverShapeConfig\":{\"ocpus\":1,\"memoryInGBs\":16},\"executorShapeConfig\":{\"ocpus\":1,\"memoryInGBs\":16}}'\n",
       "    <br/><br/><b>Example command for Spark dynamic allocation :</b><br/>\n",
       "    %create_session -l python -c '{\"compartmentId\":\"Data Flow Run resource compartment OCID\",\"displayName\":\"SessionApp\",\"sparkVersion\":\"3.2.1\",\"driverShape\":\"VM.Standard2.1\",\"executorShape\":\"VM.Standard2.1\",\"numExecutors\":1,\"configuration\":{ \"spark.dynamicAllocation.enabled\":\"true\", \"spark.dynamicAllocation.shuffleTracking.enabled\":\"true\", \"spark.dynamicAllocation.minExecutors\":\"1\", \"spark.dynamicAllocation.maxExecutors\":\"4\", \"spark.dynamicAllocation.executorIdleTimeout\":\"60\", \"spark.dynamicAllocation.schedulerBacklogTimeout\":\"60\", \"spark.dataflow.dynamicAllocation.quotaPolicy\":\"min\" }}'\n",
       "    </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>activate_session</td>\n",
       "    <td  style=\"text-align:left\">%activate_session -l python -c '{\"compartmentId\":\"Data Flow Run resource compartment OCID\",\"displayName\":\"SessionApp\",\"applicationId\":\"Existing sessionId to activate.\"}'</td>\n",
       "    <td  style=\"text-align:left\">Activate session by providing existing sessionId.</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>use_session</td>\n",
       "    <td  style=\"text-align:left\">%use_session -s {sessionId}</td>\n",
       "    <td  style=\"text-align:left\">To use already existing active session.</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>status</td>\n",
       "    <td  style=\"text-align:left\">%status</td>\n",
       "    <td  style=\"text-align:left\">Outputs current session status.</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>update_session</td>\n",
       "    <td  style=\"text-align:left\">%update_session -i '{\"maxDurationInMinutes\": 4896,\"idleTimeoutInMinutes\": 4888}'</td>\n",
       "    <td  style=\"text-align:left\">Updates current active session[not session config] for max duration or idle time out.</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>stop_session</td>\n",
       "    <td  style=\"text-align:left\">%stop_session</td>\n",
       "    <td  style=\"text-align:left\">Stops current active session. One active session should be associated with current notebook to stop.</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>config</td>\n",
       "    <td  style=\"text-align:left\">%config</td>\n",
       "    <td  style=\"text-align:left\">Outputs current session configuration.</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>configure_session</td>\n",
       "    <td  style=\"text-align:left\">%configure_session -i '{\"driverShape\": \"VM.Standard2.1\", \"executorShape\": \"VM.Standard2.1\", \"numExecutors\": 1}'</td>\n",
       "    <td  style=\"text-align:left\">Configures the session creation parameters. The force flag -f is mandatory for immediate effect of the config change, in that case session will be dropped and recreated.</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>spark</td>\n",
       "    <td  style=\"text-align:left\">%%spark -o df<br/>df = spark.read.parquet('...</td>\n",
       "    <td  style=\"text-align:left\">Executes spark commands.<br/>\n",
       "    Parameters:\n",
       "      <ul>\n",
       "        <li>-o VAR_NAME: The Spark dataframe of name VAR_NAME will be available in the %%local Python context as a\n",
       "          <a href=\"http://pandas.pydata.org/\">Pandas</a> dataframe with the same name.</li>\n",
       "        <li>-m METHOD: Sample method, either <tt>take</tt> or <tt>sample</tt>.</li>\n",
       "        <li>-n MAXROWS: The maximum number of rows of a dataframe that will be pulled from Livy to Jupyter.\n",
       "            If this number is negative, then the number of rows will be unlimited.</li>\n",
       "        <li>-r FRACTION: Fraction used for sampling.</li>\n",
       "      </ul>\n",
       "    </td>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e7f120e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up the Cluster..\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "302487a2ce764dbf9962b9ca8b522e70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster is ready..\n",
      "Starting Spark application..\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>Session ID</th><th>Kind</th><th>State</th><th>Current session</th></tr><tr><td>ocid1.dataflowapplication.oc1.iad.anuwcljsnif7xwiawhoarfxh4eo66zdbssfmltb6y2qfqgaqnifuscw7okwa</td><td>pyspark</td><td>IN_PROGRESS</td><td><a target=\"_blank\" href=\"https://console.us-phoenix-1.oraclecloud.com/data-flow/runs/details/ocid1.dataflowrun.oc1.iad.anuwcljsnif7xwian6r2kvgpkwjr7jhxat52aos2a77imom4r5j3szuhda7q?region=us-ashburn-1\">Dataflow Run</a></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n",
      "SparkContext available as 'sc'.\n"
     ]
    }
   ],
   "source": [
    "%create_session -l python -c $command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ffacccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+----------+----+----------+-----+\n",
      "|rank|          city|     state|code|population|price|\n",
      "+----+--------------+----------+----+----------+-----+\n",
      "| 295|    South Bend|   Indiana|  IN|    101190|112.9|\n",
      "|  10|Redwood Shores|California|  CA|     94065|200.9|\n",
      "+----+--------------+----------+----+----------+-----+"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "data = [[295, \"South Bend\", \"Indiana\", \"IN\", 101190, 112.9],[10, \"Redwood Shores\", \"California\", \"CA\", 94065, 200.9]]\n",
    "columns = [\"rank\", \"city\", \"state\", \"code\", \"population\", \"price\"]\n",
    "\n",
    "df1 = spark.createDataFrame(data, schema=\"rank LONG, city STRING, state STRING, code STRING, population LONG, price DOUBLE\")\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bd757f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[]"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "schemaName = \"silverzone\"\n",
    "sqlContext.sql(\"Create schema \" + schemaName)\n",
    "sqlContext.sql(\"Use \" + schemaName)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e021ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "df1.createOrReplaceTempView(\"df1_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e02c4c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>code</th>\n",
       "      <th>population</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>295</td>\n",
       "      <td>South Bend</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>IN</td>\n",
       "      <td>101190</td>\n",
       "      <td>112.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>Redwood Shores</td>\n",
       "      <td>California</td>\n",
       "      <td>CA</td>\n",
       "      <td>94065</td>\n",
       "      <td>200.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank            city       state code  population  price\n",
       "0   295      South Bend     Indiana   IN      101190  112.9\n",
       "1    10  Redwood Shores  California   CA       94065  200.9"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%spark -c sql -o rslt_view\n",
    "select  *\n",
    "from    df1_view; \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e3e2e0fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0269316b0a46432ca07fc0ae6d474b5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(HTML(value='Type:'), Button(description='Table', layout=Layout(width='70px'), st…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a934ae1ef6446f098866c41a387da5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66cfca57971e44a2a11abd7df1f4cd29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "AutoVizWidget()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from autovizwidget.widget.utils import display_dataframe\n",
    "display_dataframe(rslt_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c6c43f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78ea9829caaf47e589f2cca6ef897761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session has been stopped successfully.\n"
     ]
    }
   ],
   "source": [
    "%stop_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e5f374",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyspark32_p38_cpu_v2]",
   "language": "python",
   "name": "conda-env-pyspark32_p38_cpu_v2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
